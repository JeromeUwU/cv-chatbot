import os, re, io, json, hashlib
import streamlit as st
from groq import Groq
from dotenv import load_dotenv

# Initialisation

load_dotenv()
st.set_page_config(page_title="CV Chatbot ¬∑ J√©r√¥me TAM", page_icon="üíº", layout="centered")

GROQ_API_KEY = st.secrets.get("GROQ_API_KEY") or os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    st.error("Cl√© API manquante. Ajoute GROQ_API_KEY dans les secrets.")
    st.stop()

client = Groq(api_key=GROQ_API_KEY)
DEFAULT_MODEL = "llama-3.3-70b-versatile"
CV_TEXT = st.secrets.get("CV_TEXT", "").strip()

MAX_QUESTIONS = 10  




# System prompt 
def build_system_prompt(cv_text: str, style: str) -> str:
    cv_snippet = cv_text[:6000]  # limite tokens
    base = f"""
Tu joues le r√¥le du candidat dont le CV suit, et tu r√©ponds comme en entretien.
- Langue : si l'interlocuteur parle fran√ßais ‚Üí r√©ponds en **je** en fran√ßais naturel ; sinon en anglais avec **I**.
- Ton : bref, chaleureux, professionnel ; phrases naturelles ; 3‚Äì6 bullets max si utile ; pas de jargon inutile.

# R√àGLES ANTI-INVENTION (OBLIGATOIRES)
- **Ne jamais inventer** ce qui n‚Äôappara√Æt pas dans le CV ci-dessous : m√©triques (%, scores), dates, employeurs, titres de poste, outils, certificats, URLs, responsabilit√©s pr√©cises.
- **M√©triques** : n‚Äô√©cris *aucun* chiffre/score si le CV ne le contient pas. Si on en demande et qu‚Äôil n‚Äôy en a pas ‚Üí √©cris : ‚Äú**D‚Äôapr√®s mon CV, je n‚Äôai pas de m√©trique publi√©e sur ce point.**‚Äù
- Si une info **n‚Äôest pas pr√©sente / pas claire** dans le CV ‚Üí √©cris-le explicitement (‚Äú**D‚Äôapr√®s mon CV, ce point n‚Äôest pas pr√©cis√©.**‚Äù), puis propose un **pont cr√©dible** (bases proches, formation) et une **d√©marche** courte (cadrage ‚Üí POC ‚Üí it√©ration).
- **Pas de formulaires type** ‚ÄúVerdict‚Äù, ‚ÄúConfiance‚Äù ou scores subjectifs. Parle **comme un humain** (‚ÄúOui, parce que‚Ä¶‚Äù, ‚ÄúPas encore, mais‚Ä¶‚Äù).

# QUAND ON TE DEMANDE ‚ÄúPEUX-TU FAIRE X ?‚Äù
1) **Pr√©sent clairement dans le CV** ‚Üí r√©ponds **oui**/**non** simplement, puis **2‚Äì4 preuves concr√®tes** tir√©es du CV (exp√©riences, projets, outils).
2) **Pas mentionn√© dans le CV** ‚Üí ‚Äú**D‚Äôapr√®s mon CV, je n‚Äôai pas encore pratiqu√© X.**‚Äù
   - **Pont** : ‚ÄúEn revanche, j‚Äôai [comp√©tence/formation voisine Y] qui s‚Äôen rapproche (ex. ‚Ä¶).‚Äù
   - **Mont√©e en comp√©tence** : ‚ÄúJe peux monter vite : cadrage court, POC mesurable, puis industrialisation si valid√©.‚Äù
3) **Trop vague** ‚Üí pose **une seule** question de clarification.

# FORMAT PRATIQUE
- **Si pr√©sent** : ‚ÄúOui, sur ce point je suis √† l‚Äôaise.‚Äù + 2‚Äì4 puces de preuves tir√©es du CV.
- **Si absent** : ‚ÄúD‚Äôapr√®s mon CV, je ne l‚Äôai pas encore fait.‚Äù + 1‚Äì2 puces **pont** (bases/formation) + 1 phrase **mont√©e en comp√©tence**.
- **Si m√©triques demand√©es mais absentes** : ‚ÄúD‚Äôapr√®s mon CV, je n‚Äôai pas de m√©trique publi√©e sur ce sujet.‚Äù

CV (verbatim) :
---
{cv_snippet}
---

# Gabarits (FR)

## Comp√©tence clairement pr√©sente
"Oui, sur ce point je suis √† l‚Äôaise.
- [Preuve 1 tir√©e du CV]
- [Preuve 2 tir√©e du CV]
- [Outil/techno pertinente]
Si besoin, je peux d√©tailler un exemple concret."

## Comp√©tence non mentionn√©e dans le CV (pont formation/bases)
"D‚Äôapr√®s mon CV, je n‚Äôai pas encore pratiqu√© X directement.
En revanche, j‚Äôai des bases proches :
- [Module/projet/outil voisin 1]
- [Voisin 2]
Je peux monter vite en comp√©tence : cadrage court, POC mesurable, puis industrialisation."

## Question trop vague
"Pour √™tre pr√©cis, vous pensez √† quel contexte pour X ? (ex : outil attendu, volume de donn√©es, d√©lai)"
"""
    prefix = "R√©ponds en fran√ßais, √† la premi√®re personne (je).\n" if style == "pro (FR)" else "Answer in English, first person (I).\n"
    return prefix + base






# UI ‚Äî Sidebar
st.sidebar.title("‚öôÔ∏è Options")

sys_style = st.sidebar.selectbox("Style de r√©ponse", ["pro (FR)", "pro (EN)"], index=0)


#  Init session
def user_count() -> int:
    return sum(1 for m in st.session_state.messages if m["role"] == "user")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": build_system_prompt(CV_TEXT, sys_style)}]
    st.session_state.blocked = False  

# Rebuild prompt si style change
if st.session_state.get("sys_style") != sys_style:
    st.session_state.messages[0] = {"role": "system", "content": build_system_prompt(CV_TEXT, sys_style)}
    st.session_state.sys_style = sys_style

# √âtat blocage dur 
asked = user_count()
if asked >= MAX_QUESTIONS:
    st.session_state.blocked = True


#  En-t√™te + compteur + verrou

st.title("üíº CV ‚Äî J√©r√¥me TAM")
st.caption("Limite stricte √† 10 questions par session.")

remaining = max(0, MAX_QUESTIONS - asked)
st.info(f"Questions restantes : **{remaining}/{MAX_QUESTIONS}**")
st.progress(asked / MAX_QUESTIONS if MAX_QUESTIONS else 0.0)

if st.session_state.blocked:
    st.error("Limite atteinte. Le chat est verrouill√© pour cette session.")
    disabled_all = True
else:
    disabled_all = False


# Historique 

for m in st.session_state.messages:
    if m["role"] == "system":
        continue
    with st.chat_message("user" if m["role"] == "user" else "assistant"):
        st.markdown(m["content"])


# Suggestions (d√©sactiv√©es si blocage)

with st.expander("üí° Suggestions", expanded=True):
    cols = st.columns(3)
    examples = [
        "Peux-tu r√©sumer le profil de J√©r√¥me en 3 phrases ?",
        "Pr√©pare 5 bullets pour 'Parlez-moi de vous'.",
        "R√©ponses types : forces, faiblesses, pr√©tentions salariales.",
        "Donne 3 exemples STAR (Situation/T√¢che/Action/R√©sultat).",
        "Pitch FR puis traduction EN.",
        "Liste des projets concrets de J√©r√¥me (avec m√©triques).",
    ]
    for i, ex in enumerate(examples):
        if cols[i % 3].button(ex, use_container_width=True, key=f"sugg_{i}", disabled=disabled_all):
            st.session_state.user_prefill = ex


# Groq streaming

def stream_groq(messages, model_name):
    resp = client.chat.completions.create(
        model=model_name,
        messages=messages,
        temperature=0.35,   
        stream=True,
    )
    for chunk in resp:
        if chunk.choices:
            delta = chunk.choices[0].delta
            if delta and getattr(delta, "content", None):
                yield delta.content


#  Input (verrouill√© si blocage)

placeholder = "Pose une question li√©e au profil (comp√©tences, exp√©riences, soft skills, MLOps, salaire, dispo)‚Ä¶"
prompt = st.chat_input(placeholder=placeholder, key="chat_input", disabled=disabled_all)

if prompt is None and "user_prefill" in st.session_state and not disabled_all:
    prompt = st.session_state.pop("user_prefill")


#  Gate & ex√©cution 

if prompt:

    if user_count() >= MAX_QUESTIONS or st.session_state.blocked:
        st.session_state.blocked = True
        with st.chat_message("assistant"):
            st.error("Limite atteinte. Le chat est verrouill√© pour cette session.")
    else:
            
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            stream_area = st.empty()
            chunks = stream_groq(st.session_state.messages, DEFAULT_MODEL)
            full = stream_area.write_stream(chunks)

        st.session_state.messages.append({"role": "assistant", "content": full})

            
        if user_count() >= MAX_QUESTIONS:
            st.session_state.blocked = True
            st.toast("‚ö†Ô∏è Limite atteinte : le chat est d√©sormais verrouill√©.")